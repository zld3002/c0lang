Null pointer checking in C0
Jason Koenig, Frank Pfenning
Transcribed by fp, Sat Apr 9, 2011
Updated to ve by fp, Tue Apr 26, 2011 (w. Karl Naden)

In lieu of trying to develop tools for full verification,
we can consider subproblems which may have algorithmic
and intuitive solutions that could be helpful to the
students.  Once such subproblem is pointer analysis in
order to identify places where null pointers may be
accidentally dereferenced.

As usual, we proceed by first proposing a static type
system to capture the analysis, and then develop
a separate inference algorithm.  The basic idea
is based on abstract interpretation over a 4-valued
lattice, although in the educational setting a richer
lattice may be of some use [citation?].

There are a number of open questions, some listed
at the end.

We use the following types:

t* - pointer
t& - non-null pointer [note: changed from Cyclone to indicate reference]
t! - null pointer
bot - impossible

in the lattice

       t*
      / \
     t! t&
      \ /
      bot

  t <: t' - t is a subtype of t'
  t /\ t' - greatest lower bound of t and t'
  t \/ t' - least upper bound of t and t'

We extend these pointwise to whole contexts of matching variables
declarations.

Judgments:

G |- s stmt    [as of v2 folded into G ; s stmt |> G', see below]
G |- e : t     (for expression e)
G |- lv -:- t  (for lvalue lv)

Some rules:

x : t in G
----------
G |- x : t

Pointers:

------------------
G |- alloc(t) : t&

G |- e : t&
-----------
G |- *e : t 

--------------
G |- NULL : t!

Subsumption:

G |- e : t
t <: t'
----------- [covariance for exps]
G |- e : t'

G |- lv -:- t'
t <: t'
-------------- [contravariance for lvalues]
G |- lv -:- t

Conditions: conditionals require two new judgments in order to derive
new information about the variables declared in the context.  We
write:

G ; e true |> G'   Given G and e is true, we know G'
G ; e false |> G'  Given G and e is false, we know G'

Some rules for these are shown below.  For conditions we exploit
subsumption so we can given both branches the same type t.
Otherwise (and in an algorithm) we would take the least
upper bound of the types of the two branches.

G |- e1 : bool
G ; e1 true |> G2
G2 |- e2 : t
G ; e1 false |> G3
G3 |- e3 : t
-----------------------
G |- (e1 ? e2 : e3) : t

--------------------------------- +sym NULL == p
G ; p == NULL true |> G /\ (p:t!)

--------------------------------- +sym NULL != p
G ; p != NULL true |> G /\ (p:t&)

G ; c1 true |> G1
G1 ; c2 true |> G2
------------------
G ; c1 && c2 true |> G2

G ; c1 true |- G1
G ; c1 false |- G1'
G1' ; c2 true |- G2
-----------------------------
G ; c1 || c2 true |> G1 \/ G2

------------------
G ; true true |> G

--------------------------
G ; false true |> G /\ bot

G ; c false |> G'
-----------------
G ; !c true |> G'

G ; e1 true |> G1
G1 ; e2 true |> G2
G ; e1 false |> G1'
G1' ; e3 true |> G2'
------------------------------------
G ; (e1 ? e2 : e3) true |> G2 \/ G2'

The rules for G ; c false |> G' are dual

[Obsolete, as of v2
  Statements:

  G |- lv -:- t
  G |- e : t
  ----------------
  G |- lv = e stmt
]

What can we learn from statements?

New judgment  G ; s |> G'

Knowing G, after executing s, we know G'.  G and G' will be defined on
the same set of variables.  We always have G :> G', that is, we only
information.  We check that s is a valid statement at the same time,
so the judgment G |- s stmt is not obsolete.

G |- e : bool
G ; e true |> G1
G1 ; s1 |> G1'
G ; e false |> G2
G2 ; s2 |> G2'
------------------------------- IF
G ; if(e, s1, s2) |> G1' \/ G2'

G |- x -:- t'
G |- e : t
t <: t'
------------------------- ASSIGN
G ; x = e |> G /\ (x:t)

G |- inv : bool
G ; inv true |> G'
G = G'             (loop invariant should be entailed by knowledge)
G' <: Ginv         (invariant context Ginv could be weaker than G')
Ginv |- e : bool
Ginv ; e true |> G1
G1 ; s |> G2
G2 <: Ginv
Ginv ; e false |> Gexit
----------------------------- WHILE (without break or continue in body)
G ; while(inv, e, s) |> Gexit

G |- e : bool
G ; e true |> G'
G = G'                (assertion should be entailed already)
-------------------- ASSERT
G ; assert(e) |> G'

G |- e : t            (in function t g(t1 x1,...,tn xn))
------------------------- RETURN
G ; return(e) |> G /\ bot  (unreachable: each variable has type bot)

G ; s1 |> G1
G1 ; s2 |> G2
------------------- SEQ
G ; (s1 ; s2) |> G2 


------------ NOP
G ; nop |> G

Question:

How do we handle function calls as expressions
or statements?  Must treat pre/postconditions specially.
[this is my attempt as of v2 -fp]

t' g(t x)
//@requires c(x);
//@ensures c'(x,\result);
  ;
G |- e : targ
targ <: t
x:targ ; c(x) true |> x:targ'
targ = targ'                                (precondition is implied)
x:targ', r:t' ; c'(x,r) true |> x:_, r:tres  (ignore info on x)
------------------------------------------
G |- g(e) : tres

To be sound, the function should not have an effect
on the argument.

Further work:

How do we handle/control for effects on function arguments?

We need to add structs (and perhaps arrays) to see
how this interacts with our analysis so far, especially
since this is what we have to deal with in most applications.

How do we handle function calls in conditions?
Create summary for boolean functions about what
we know about its arguments when it returns true,
and what we know when it returns false.  Still to
be worked out.

Here are some thoughts [by fp, after the meeting]:

Perhaps we can handle the problem
of "inverting" the information that the result of some
function call must be true by using an explicit or
implicit postcondition.  For example:

bool g(int* x) {
  return x != NULL;
}

could be annotated (either by programmer or by us)
as

bool g(int* x)
//@requires true;
//@ensures \result ? x != NULL : !(x != NULL);
  ;

Then we could, in general, given

bool g(t x)
//@requires c(x);
//@ensures c'(x, \result);
  ;

use the following two rules:

G ; c'(e,true) true |> G'
--------------------------
G ; g(e) true |> G'

G ; c'(e,false) false |> G'
----------------------------
G ; g(e) false |> G'

What do you think?




